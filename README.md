# Awesome-Masked-Autoencoder
A curated list of awesome masked autoencoder papeprs in self-supervised learning

We have currently finished a survey on masked autoencoder.

We will wrap it up as soon as possible (stay tuned!)

### Two-stage BEiT and its improved variants
[BEiT: Bert pre-training of image transformers](https://arxiv.org/pdf/2106.08254.pdf) \
[mc-BEiT: Multi-choice discretization for image bert pre-training](https://arxiv.org/abs/2203.15371) \
[PeCo: Perceptual codebook for bert pre-training of vision transformers](https://arxiv.org/abs/2111.12710) \
[Context autoencoder for self-supervised representation learning](https://arxiv.org/abs/2202.03026) \

### End-to-end Maksed Autoencoder
[Masked Autoencoders Are Scalable Vision Learners](https://arxiv.org/abs/2111.06377) \
[SimMIM: A Simple Framework for Masked Image Modeling](https://arxiv.org/abs/2111.09886) \

[Green hierarchical vision transformer for masked image modeling](https://arxiv.org/abs/2205.13515) \
[Uniform masking: Enabling
mae pre-training for pyramid-based vision transformers with locality](https://arxiv.org/abs/2205.10063) \
[Hivit: Hierarchical vision transformer meets masked image modeling](https://arxiv.org/pdf/2205.14949) \
[Efficient self-supervised vision pretraining with local masked reconstruction](https://arxiv.org/abs/2206.00790) \
[Object-wise Masked Autoencoders for Fast Pre-training](https://arxiv.org/abs/2205.14338) \
[MixMIM: Mixed and masked image modeling for efficient visual representation learning](https://arxiv.org/abs/2205.13137) \
[MixMIM: Mixed and masked image modeling for efficient visual representation learning](https://arxiv.org/abs/2205.13137) \
[ConvMAE: Masked Convolution Meets Masked Autoencoders](https://arxiv.org/abs/2205.03892) \
[Unleash-
ing vanilla vision transformer with masked image modeling for
object detection](https://arxiv.org/abs/2205.03892) \
[Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection](https://arxiv.org/abs/2204.02964) \
[Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN](https://arxiv.org/abs/2205.13943v2) \
[Corrupted Image Modeling for Self-Supervised Visual Pre-Training](https://arxiv.org/abs/2202.03382) \
[Are Large-scale Datasets Necessary for Self-Supervised Pre-training?](https://arxiv.org/abs/2112.10740) \
[On Data Scaling in Masked Image Modeling](https://arxiv.org/abs/2206.04664) \
[Domain Invariant Masked Autoencoders for Self-supervised Learning from Multi-domains](https://arxiv.org/abs/2205.04771) \
[MultiMAE: Multi-modal Multi-task Masked Autoencoders](https://arxiv.org/pdf/2204.01678) \
[Beyond Masking: Demystifying Token-Based Pre-Training for Vision Transformers](https://arxiv.org/abs/2203.14313) \
[Masked frequency modeling for self-supervised visual pre-training](https://arxiv.org/abs/2206.07706) \
[How to understand masked autoencoders?](https://arxiv.org/pdf/2202.03670.pdf) \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \
[]() \

